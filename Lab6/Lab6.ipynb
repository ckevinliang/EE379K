{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6\n",
    "# Kevin Liang - kgl392\n",
    "# Matthew Tan - mmt2338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sympy\n",
    "import scipy\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import collections\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix\n",
    "from sklearn.cross_decomposition import PLSRegression, PLSSVD\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, LinearRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.cross_decomposition import PLSRegression, PLSSVD\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean beta hat: 0.745447730474\n",
      "Variance beta hat: 9.52456950954\n",
      "\n",
      "Alpha / MSE\n",
      "0.01 : 2.87045193125e-05\n",
      "0.1 : 0.00874055532396\n",
      "1 : 0.119996489473\n",
      "10 : 1.35616856545\n",
      "100 : 16.3178681573\n",
      "200 : 23.0268307572\n",
      "300 : 20.6278303802\n",
      "400 : 38.7276113761\n",
      "500 : 46.4410933092\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFXCAYAAACP5RboAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f0bda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 1\n",
    "\n",
    "# helper function to calculate rmse of a model\n",
    "def rmse_cv(model, X, y):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n",
    "beta_hat_components = []\n",
    "\n",
    "for _ in range(100):\n",
    "    X = np.random.randn(51,50)\n",
    "    noise = np.asarray([np.random.normal(0,.25,51)]).transpose()\n",
    "    beta = np.asarray([[1]*50]).transpose()\n",
    "    y = np.dot(X, beta) + noise\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr = lr.fit(X,y)\n",
    "    beta_hat_components.append(lr.coef_[0,0])\n",
    "\n",
    "mean_beta_hat = np.mean(beta_hat_components)\n",
    "variance_beta_hat = np.var(beta_hat_components)\n",
    "\n",
    "print \"Mean beta hat: \" + str(mean_beta_hat)\n",
    "print \"Variance beta hat: \" + str(variance_beta_hat) + '\\n'\n",
    "\n",
    "alphas = [0.01,0.1,1,10,100,200,300,400,500]\n",
    "performance = {}\n",
    "performance_list = []\n",
    "for alpha in alphas:\n",
    "    X = np.random.randn(51,50)\n",
    "    noise = np.asarray([np.random.normal(0,.25,51)]).transpose()\n",
    "    beta = np.asarray([[1]*50]).transpose()\n",
    "    y = np.dot(X, beta) + noise\n",
    "    \n",
    "    rr = Ridge(alpha)\n",
    "    rr = rr.fit(X,y)\n",
    "    y_pred = rr.predict(X)\n",
    "    rmse = mean_squared_error(y,y_pred)\n",
    "    performance[alpha] = rmse\n",
    "    performance_list.append(rmse)\n",
    "\n",
    "performance = collections.OrderedDict(sorted(performance.items(), key=lambda t: t[0]))\n",
    "print \"Alpha / MSE\"\n",
    "for x in performance:\n",
    "    print str(x) + \" : \" + str(performance[x])\n",
    "\n",
    "plt.xlabel(\"Alphas\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.plot(alphas,performance_list)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Q: What do you observe?\n",
    "A : As the number of alphas increase the mse also increase. It seems to level out at about an alpha of 400. The variance is very high since I am running 100 runs; however, with fewer runs the variance ends up being very low. \n",
    "\n",
    "# Q: As you increase lambda is the model becoming more simple or more complex?\n",
    "A: Based on the nature of a ridge regression, as the lambda increases the model becomes simpler and as the lambda decreases the model becomes more complex. \n",
    "\n",
    "\n",
    "# Q: As you increase lambda is performance becoming better or worse?\n",
    "A: The MSE steadily increases as the alphas increase. The best alpha will be between 0.1 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for calculating test error\n",
    "def testError(true, predict):\n",
    "    sum = 0\n",
    "    for x in range(len(true)):\n",
    "        sum += abs(true[x] - predict[x])\n",
    "    return (float(sum)/float(len(true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part B: Linear Model\n",
      "Linear Regression test error: 624.660775993\n",
      "\n",
      "Part C: Ridge Regression\n",
      "RidgeCV test error: 622.457778984\n",
      "\n",
      "Part D: Lasso Regression\n",
      "LassoCV test error: 619.474419861\n",
      "LassoCV Non-zero coefficients: 12\n",
      "\n",
      "Part E: PCR\n",
      "# of Components / Negative Cross Val Score / Variance\n",
      "1 151.450077808 0.464469281632\n",
      "2 142.210329382 0.421237161864\n",
      "3 137.360385262 0.066225839805\n",
      "4 136.131576067 0.0245646109023\n",
      "5 133.042173388 0.0107896991109\n",
      "6 128.891589544 0.00689200685852\n",
      "7 121.373433483 0.00489320342696\n",
      "8 118.462067767 0.000561970743338\n",
      "9 106.776980961 0.000354534653025\n",
      "10 105.721427804 5.48810197432e-06\n",
      "11 105.135562708 2.65542799489e-06\n",
      "12 104.423597828 1.89712912486e-06\n",
      "13 103.847556874 8.58009222647e-07\n",
      "14 103.637208138 3.9755368977e-07\n",
      "15 102.991410149 2.80811922305e-07\n",
      "16 101.305593475 1.13071667094e-07\n",
      "17 101.305593487 8.98421317377e-10\n",
      "\n",
      "Value of M: 3\n",
      "PCR test error: 642.966739894\n",
      "\n",
      "Part F: PLS\n",
      "# of Components / Negative Cross Val Score \n",
      "1 -0.0926313503776\n",
      "2 -0.053376231728\n",
      "3 0.00142152286444\n",
      "4 -0.0317977435785\n",
      "5 -0.0124549026524\n",
      "6 -0.0149845251569\n",
      "7 -0.0276904097182\n",
      "8 -0.0355531109267\n",
      "9 -0.0307469519267\n",
      "10 -0.0245363562961\n",
      "11 -0.0217875410131\n",
      "12 -0.0195114814534\n",
      "13 -0.0199874733731\n",
      "14 -0.0201550890055\n",
      "15 -0.0205301026122\n",
      "16 -0.0202378828971\n",
      "17 -0.0202577869141\n",
      "\n",
      "Value of M: 1\n",
      "PLS test error: 2175.77474739\n"
     ]
    }
   ],
   "source": [
    "# Question 2 \n",
    "\n",
    "path = \"D:/Kevin Liang/Documents/1_UT_SENIOR/UT_AUSTIN_FALL_2017/EE_379K/Lab6/\"\n",
    "data = pd.read_csv(path + \"College.csv\", header = 0, index_col = 0)\n",
    "\n",
    "X = data.drop([\"Apps\"], axis = 1).replace({\"Yes\" : 1, \"No\" : 0})\n",
    "y = data.loc[:,\"Apps\"]\n",
    "\n",
    "X.fillna(X.mean())\n",
    "# Part a\n",
    "X_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Part b\n",
    "lr = LinearRegression()\n",
    "lr = lr.fit(X_train, Y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print \"Part B: Linear Model\"\n",
    "print \"Linear Regression test error: \" + str(testError(Y_test, y_pred)) + '\\n'\n",
    "\n",
    "# Part c\n",
    "alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\n",
    "r_cv = RidgeCV(alphas = alphas)\n",
    "r_cv = r_cv.fit(X_train, Y_train)\n",
    "y_pred = r_cv.predict(X_test)\n",
    "\n",
    "print \"Part C: Ridge Regression\"\n",
    "print \"RidgeCV test error: \" + str(testError(Y_test, y_pred)) + '\\n'\n",
    "\n",
    "# Part d\n",
    "alphas = [10, 1, 0.1, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005]\n",
    "l_cv = LassoCV(alphas = alphas)\n",
    "l_cv = l_cv.fit(X_train, Y_train)\n",
    "y_pred = l_cv.predict(X_test)\n",
    "\n",
    "\n",
    "non_zero_coefs = sum(l_cv.coef_ < 0.1)\n",
    "\n",
    "print \"Part D: Lasso Regression\"\n",
    "print \"LassoCV test error: \" + str(testError(Y_test, y_pred))\n",
    "print \"LassoCV Non-zero coefficients: \" + str(non_zero_coefs) + '\\n'\n",
    "\n",
    "# Part e\n",
    "\n",
    "print \"Part E: PCR\"\n",
    "components = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "\n",
    "component = 0\n",
    "total_variance = 0\n",
    "\n",
    "print \"# of Components / Negative Cross Val Score / Variance\"\n",
    "for x in components:\n",
    "    pca = PCA(n_components = x, svd_solver = \"full\")\n",
    "    cv_score = -1 * cross_val_score(pca, X, y, cv=10).mean()\n",
    "    pca  = pca.fit(X_train, Y_train)\n",
    "    print x, cv_score, pca.explained_variance_ratio_[-1]\n",
    "    if total_variance < .9:\n",
    "        total_variance += pca.explained_variance_ratio_[-1]\n",
    "        component = x\n",
    "\n",
    "pcr = LinearRegression()\n",
    "pcr = pcr.fit(X_train.iloc[:,:component+1], Y_train)\n",
    "X_test_pcr = X_test.iloc[:,:component+1]\n",
    "y_pred = pcr.predict(X_test_pcr)\n",
    "\n",
    "print\n",
    "print \"Value of M: \" + str(component)\n",
    "print \"PCR test error: \" + str(testError(Y_test, y_pred)) + '\\n'\n",
    "\n",
    "# Part f\n",
    "print \"Part F: PLS\"\n",
    "component = 0\n",
    "score = 0\n",
    "print \"# of Components / Negative Cross Val Score \"\n",
    "for x in components:\n",
    "    pls = PLSRegression(n_components = x)\n",
    "    cv_score = -1 * cross_val_score(pls, X, y, cv=10).mean()\n",
    "    pca  = pca.fit(X_train, Y_train)\n",
    "    if cv_score < score:\n",
    "        score = cv_score\n",
    "        component = x\n",
    "    print x, cv_score\n",
    "    \n",
    "pls = PLSRegression(n_components = component)\n",
    "pls = pls.fit(X_train, Y_train)\n",
    "y_pred = pls.predict(X_test)\n",
    "\n",
    "print\n",
    "print \"Value of M: \" + str(component)\n",
    "print \"PLS test error: \" + str(testError(Y_test, y_pred)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part E (PCR)\n",
    "\n",
    "To determine the M value for PCR, I utilized the Negative cross val score and variance of the data. The negative cross val score decreased as the number of components increased so based on the negative cross val score the more components the better the regressional model; however, I based the M value on variance as well. I chose the number of components once 90% of the variance of the data was represented. \n",
    "\n",
    "\n",
    "# Part F\n",
    "\n",
    "I chose the M value for PLS based on the negative cross val score. I chose the largest negative cross val score to determine the number of components to use and thus the M value.\n",
    "\n",
    "# Part G\n",
    "\n",
    "Most of the test errors for all of the different regressional models are about the same; however, PLS has a very different test error of 2175 when the other test errors fall between 600 - 650. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression CV error: 166.027381249\n",
      "\n",
      "Lasso Regression CV error: 148.449354001\n",
      "\n",
      "# of componenents for PCR: 2\n",
      "CV_score for the given number of components: 39.3688727427\n"
     ]
    }
   ],
   "source": [
    "# Question 3 \n",
    "\n",
    "df = pd.read_csv(path + \"boston.csv\")\n",
    "X = df.loc[:,(\"zn\", \"indus\", \"chas\", \"nox\", \"rm\", \"age\", \"dis\", \"rad\", \"tax\", \"ptratio\", \"black\", \"lstat\", \"medv\")]\n",
    "Y = df.loc[:,\"crim\"]\n",
    "X_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(X, Y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Ridge Regression\n",
    "boston_ridge = RidgeCV(alphas=[0.001, 0.01, .05, 0.1, 0.5, 0.7, 0.9, 1, 2, 5, 7, 10, 20, 30, 40, 45, 50, 55, 60, 70])\n",
    "boston_ridge.fit(X_train,Y_train)\n",
    "bridge_cv =  cross_val_score(estimator=boston_ridge, X=X, y=Y, cv=10)\n",
    "print \"Ridge Regression CV error: \" + str(-1 * bridge_cv.mean()) + \"\\n\"\n",
    "\n",
    "#Lasso Regression\n",
    "boston_lasso = LassoCV(alphas=[10, 1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005])\n",
    "boston_lasso.fit(X_train,Y_train)\n",
    "blasso_cv = cross_val_score(estimator=boston_lasso, X=X, y=Y, cv=10)\n",
    "print \"Lasso Regression CV error: \" + str(-1 * blasso_cv.mean()) + \"\\n\"\n",
    "\n",
    "#PCR \n",
    "components = [1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "\n",
    "component = 0\n",
    "total_variance = 0\n",
    "score = 0\n",
    "\n",
    "for x in components:\n",
    "    pca = PCA(n_components = x, svd_solver = \"full\")\n",
    "    cv_score = -1 * cross_val_score(pca, X, Y, cv=10).mean()\n",
    "    pca  = pca.fit(X_train, Y_train)\n",
    "    #print x, cv_score, pca.explained_variance_ratio_[-1]\n",
    "    if total_variance < .9:\n",
    "        total_variance += pca.explained_variance_ratio_[-1]\n",
    "        score = cv_score\n",
    "        component = x\n",
    "        \n",
    "print \"# of componenents for PCR: \" + str(component) #number of components\n",
    "print \"CV_score for the given number of components: \" + str(cv_score)  #the score given the number of components\n",
    "boston_pcr = LinearRegression()\n",
    "boston_X_test_pcr = X_test.iloc[:,:component+1]\n",
    "boston_pcr = cross_val_score(estimator=boston_pcr, X=X, y=Y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0075      0.01388889  0.03703704  0.          0.        ]\n",
      "[ 0.005       0.01388889  0.03703704  0.          0.        ]\n",
      "[ 0.005  0.     0.     0.     0.   ]\n",
      "[ 0.005  0.     0.     0.     0.   ]\n",
      "[ 0.0075      0.04166667  0.          0.          0.        ]\n",
      "[ 0.01        0.04166667  0.          0.          0.        ]\n",
      "[ 0.005       0.02777778  0.          0.          0.        ]\n",
      "[ 0.0075      0.01388889  0.          0.          0.        ]\n",
      "[False  True False False  True False  True  True False  True False  True\n",
      "  True]\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "# Problm 3 - Continued (Subset Selection code)\n",
    "# Recursive Feature Elimination\n",
    "\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "# converting Y to a useable data type\n",
    "Y_int  = (1000*Y).astype(int) \n",
    "minimum = 1000.0;\n",
    "a = [];\n",
    "# create the RFE model and select 3 attributes\n",
    "for i in range(5,13):\n",
    "    rfe = RFE(estimator=model, n_features_to_select=i)\n",
    "    rfe = rfe.fit(X, Y_int)\n",
    "    rfe_cv = cross_val_score(rfe, X, Y_int, cv=5)\n",
    "    print rfe_cv\n",
    "    if(rfe_cv.mean() < minimum):\n",
    "        a = rfe.support_\n",
    "        minimum = rfe_cv.mean()\n",
    "print a\n",
    "print minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3 part B:\n",
    "\n",
    "The model that best performed on the boston.csv data set was the SubsetSelection model, particularly using 7 or 8 of the features. Less than 5 features were not tested since 5 is the standard number of folds (cv=5), and you cannot have fewer features than folds. \n",
    "\n",
    "In particular the desired features are as follows: indus, rm, dis, rad, ptratio, lstat, medv\n",
    "\n",
    "This is decided due to having the smallest CV error (0.001) out of all regression options chosen. The next best regression option was Ridge Regression (0.0791994546446 CV Error value).\n",
    "\n",
    "Problem 3 part C:\n",
    "\n",
    "The chosen model does not include all features, as the purpose of subset selection is to discard noisy/unrelated features in order to simplify the data set and regression. In our case, 6 of the 13 were not deemd relevant features, with 7 remaining and listed above in part B.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
